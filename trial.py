# -*- coding: utf-8 -*-
"""TRIAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15yUzEGogmwWMfMFtmJ19SVU7JBG_Ei3T
"""

# Cell 1: install required packages# Correct install
!pip install -q transformers accelerate huggingface_hub torch streamlit pyngrok gTTS==2.5.4

pip install accelerate

from huggingface_hub import login
login(token="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")
print("Loaded Token Successfully")

import os
import base64
import streamlit as st
from gtts import gTTS
from io import BytesIO
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

model_name = "ibm-granite/granite-3.1-3b-a800m-instruct"

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Load model with automatic memory-efficient loading
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="auto",          # Auto-assign layers to GPU/CPU
    torch_dtype="auto",         # Use appropriate dtype (fp16/fp32)
    low_cpu_mem_usage=True      # Key: load without running out of memory
)

# Create text-generation pipeline (do NOT pass `device`)
generator = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer
)

def rewrite_text_with_tone(original_text, tone="Neutral", max_new_tokens=200):
    prompt = f"Rewrite the following text in a {tone} tone, keeping the meaning the same:\n\n{original_text}\n\nRewritten:"
    response = generator(prompt, max_new_tokens=max_new_tokens, do_sample=True, temperature=0.7)
    return response[0]["generated_text"]

from gtts import gTTS

def synthesize_gtts(text, voice="Lisa", filename="output.mp3"):
    """
    Simulated 3 voices:
    Lisa: default female
    Michael: slower male-like
    Allison: UK accent
    """
    if voice == "Lisa":
        tts = gTTS(text=text, lang="en", slow=False)
    elif voice == "Michael":
        tts = gTTS(text=text, lang="en", slow=True)
    elif voice == "Allison":
        tts = gTTS(text=text, lang="en-uk", slow=False)
    else:
        tts = gTTS(text=text, lang="en", slow=False)
    tts.save(filename)
    return filename

def make_mp3_download_bytes(mp3_bytes, filename="echoverse.mp3"):
    bio = BytesIO(mp3_bytes)
    bio.seek(0)
    return bio, filename

def read_txt_file(file):
    return file.read().decode("utf-8")

pip install whisper

from pyngrok import ngrok

# Replace YOUR_NGROK_AUTHTOKEN with your actual token
ngrok.set_auth_token("32uf7z5Hpde1Iu4LLg2WCIoCDm8_84QrpWS5E5yqDe285aBA8")

pip install deep-translator gTTS transformers streamlit

def load_translator(src, tgt):
    try:
        model_name = f"Helsinki-NLP/opus-mt-{src}-{tgt}"
        tokenizer = MarianTokenizer.from_pretrained(model_name, use_auth_token=True)
        model = MarianMTModel.from_pretrained(model_name, use_auth_token=True)
        return pipeline("translation", model=model, tokenizer=tokenizer)
    except Exception as e:
        st.error(f"Could not load translator for {src}->{tgt}: {e}")
        return None

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# from gtts import gTTS
# from io import BytesIO
# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
# from deep_translator import GoogleTranslator
# import tempfile
# import os
# 
# # ---- Granite for English rewriting ----
# model_name = "ibm-granite/granite-3.1-3b-a800m-instruct"
# tokenizer = AutoTokenizer.from_pretrained(model_name)
# model = AutoModelForCausalLM.from_pretrained(
#     model_name,
#     device_map="auto",
#     torch_dtype="auto",
#     low_cpu_mem_usage=True
# )
# generator = pipeline("text-generation", model=model, tokenizer=tokenizer)
# 
# # ---- ASR (Speech-to-Text) pipeline loader (cached) ----
# @st.cache_resource
# def load_asr_pipeline():
#     # âœ… Add chunk_length_s to avoid long-audio (>30s) crash
#     return pipeline(
#         "automatic-speech-recognition",
#         model="openai/whisper-small",
#         chunk_length_s=30
#     )
# 
# asr_pipeline = load_asr_pipeline()
# 
# # ---- Functions ----
# def rewrite_text_with_tone(original_text, tone="Neutral", max_new_tokens=200):
#     prompt = f"Rewrite the following text in a {tone} tone, keeping the meaning the same:\n\n{original_text}\n\nRewritten:"
#     response = generator(prompt, max_new_tokens=max_new_tokens, do_sample=True, temperature=0.7)
#     return response[0]["generated_text"]
# 
# def translate_text(text, target_lang):
#     try:
#         return GoogleTranslator(source="en", target=target_lang).translate(text)
#     except Exception as e:
#         return f"[Translation failed: {str(e)}]"
# 
# def synthesize_gtts(text, voice="Lisa", filename="output.mp3", lang="en"):
#     if lang == "en":
#         if voice == "Lisa":
#             tts = gTTS(text=text, lang="en", slow=False)
#         elif voice == "Michael":
#             tts = gTTS(text=text, lang="en", slow=True)
#         elif voice == "Allison":
#             tts = gTTS(text=text, lang="en-uk", slow=False)
#         else:
#             tts = gTTS(text=text, lang="en", slow=False)
#     elif lang == "ta":
#         tts = gTTS(text=text, lang="ta", slow=False)
#     elif lang == "hi":
#         tts = gTTS(text=text, lang="hi", slow=False)
#     else:
#         tts = gTTS(text=text, lang="en", slow=False)
# 
#     tts.save(filename)
#     return filename
# 
# def make_mp3_download_bytes(mp3_bytes, filename="echoverse.mp3"):
#     bio = BytesIO(mp3_bytes)
#     bio.seek(0)
#     return bio, filename
# 
# def read_txt_file(file):
#     return file.read().decode("utf-8")
# 
# # ---- Streamlit UI ----
# st.set_page_config(page_title="EchoVerse ðŸŽ¶", layout="centered")
# 
# # ---- Dynamic Lavender Background (no blur) ----
# page_bg = """
# <style>
# [data-testid="stAppViewContainer"] {
#     background-image: url("https://images.unsplash.com/photo-1519677100203-a0e668c92439?auto=format&fit=crop&w=1920&q=80"); /* ðŸŽ§ headphone image */
#     background-size: cover;
#     background-position: center;
#     background-repeat: no-repeat;
# }
# 
# /* Overlay lavender tint */
# [data-testid="stAppViewContainer"]::before {
#     content: "";
#     position: absolute;
#     top: 0; left: 0;
#     width: 100%; height: 100%;
#     background: rgba(230, 230, 250, 0.6); /* lavender semi-transparent */
#     z-index: 0;
# }
# 
# /* Keep inner content clear and bright */
# [data-testid="stAppViewContainer"] > div {
#     position: relative;
#     z-index: 1;
#     color: #000000;
#     font-weight: 500;
# }
# 
# /* Bright text areas, inputs, buttons */
# .stTextArea textarea, .stTextInput input, .stDownloadButton button, .stButton button, .stSelectbox div, .stFileUploader label {
#     background-color: #ffffff !important;
#     color: #000000 !important;
#     border: 2px solid #9370DB !important; /* lavender purple border */
#     border-radius: 10px !important;
#     font-weight: 500 !important;
# }
# 
# /* Section headers */
# h1, h2, h3, h4 {
#     color: #4B0082 !important; /* deep lavender text */
#     text-shadow: 1px 1px 2px #ffffff;
# }
# </style>
# """
# st.markdown(page_bg, unsafe_allow_html=True)
# 
# st.title("EchoVerse ðŸŽ¶")
# st.write("Transform text into expressive audiobooks â€” Neutral, Suspenseful, Inspiring â€” Now in English, Tamil & Hindi")
# 
# # ---- Main text input / file upload ----
# uploaded = st.file_uploader("Upload a .txt file", type=["txt"])
# pasted = st.text_area("Or paste your text here:", height=220)
# 
# input_text = ""
# if uploaded:
#     input_text = read_txt_file(uploaded)
# elif pasted:
#     input_text = pasted
# 
# language = st.selectbox("Language", ["English", "Tamil", "Hindi"])
# tone = st.selectbox("Tone", ["Neutral", "Suspenseful", "Inspiring"]) if language == "English" else "Neutral"
# voice = st.selectbox("Voice", ["Lisa", "Michael", "Allison"]) if language == "English" else None
# max_tokens = st.slider("Approx. rewritten length (max tokens)", 100, 600, 200, step=50) if language == "English" else 200
# 
# if st.button("âœ¨ Generate Audiobook"):
#     if input_text.strip():
#         with st.spinner("Processing text..."):
#             if language == "English":
#                 rewritten = rewrite_text_with_tone(input_text, tone, max_new_tokens=max_tokens)
#                 lang_code = "en"
#             elif language == "Tamil":
#                 rewritten = translate_text(input_text, "ta")
#                 lang_code = "ta"
#             else:  # Hindi
#                 rewritten = translate_text(input_text, "hi")
#                 lang_code = "hi"
# 
#         col1, col2 = st.columns(2)
#         with col1:
#             st.subheader("Original (English)")
#             st.write(input_text[:5000])
#         with col2:
#             st.subheader(f"Translated / Rewritten ({language})")
#             st.write(rewritten[:5000])
# 
#         with st.spinner("Synthesizing audio..."):
#             mp3_file = synthesize_gtts(rewritten, voice=voice, filename="output.mp3", lang=lang_code)
# 
#         st.audio(mp3_file, format="audio/mp3")
#         with open(mp3_file, "rb") as f:
#             bio, fname = make_mp3_download_bytes(f.read(), filename=f"echoverse_{language}.mp3")
#         st.download_button("â¬‡ï¸ Download MP3", data=bio, file_name=fname, mime="audio/mp3")
# 
#         # Save history
#         if "history" not in st.session_state:
#             st.session_state.history = []
#         st.session_state.history.insert(0, {"lang": language, "tone": tone, "voice": voice if voice else "-", "rewritten": rewritten})
#     else:
#         st.warning("Please upload or paste text first.")
# 
# # ---- Past Narrations ----
# st.markdown("---")
# st.header("ðŸ“‚ Past Narrations (this session)")
# if "history" in st.session_state and st.session_state.history:
#     for i, entry in enumerate(st.session_state.history[:8]):
#         st.write(f"**{i+1}. Lang:** {entry['lang']} | **Tone:** {entry['tone']} | **Voice:** {entry['voice']}")
#         st.write(entry["rewritten"][:400] + ("..." if len(entry["rewritten"])>400 else ""))
# else:
#     st.info("No past narrations yet.")
# 
# # ---- NEW: Speech to Text (STT) ----
# st.markdown("---")
# st.header("ðŸŽ¤ Speech to Text (English / Tamil / Hindi)")
# 
# audio_file = st.file_uploader("Upload an audio file to transcribe (wav/mp3/m4a)", type=["wav", "mp3", "m4a"], key="stt_uploader")
# if audio_file is not None:
#     # Save uploaded to a temp file
#     suffix = os.path.splitext(audio_file.name)[1] or ".wav"
#     try:
#         with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
#             tmp.write(audio_file.read())
#             tmp_path = tmp.name
# 
#         with st.spinner("Transcribing audio (this may take a few seconds)..."):
#             try:
#                 asr_result = asr_pipeline(tmp_path)
#                 # ASR pipeline may return dict with 'text' or a string
#                 if isinstance(asr_result, dict) and "text" in asr_result:
#                     detected_text = asr_result["text"]
#                 elif isinstance(asr_result, str):
#                     detected_text = asr_result
#                 elif isinstance(asr_result, list):
#                     parts = []
#                     for item in asr_result:
#                         if isinstance(item, dict) and "text" in item:
#                             parts.append(item["text"])
#                         else:
#                             parts.append(str(item))
#                     detected_text = " ".join(parts).strip()
#                 else:
#                     detected_text = str(asr_result)
#             except Exception as e:
#                 detected_text = f"[Transcription failed: {e}]"
#         try:
#             os.remove(tmp_path)
#         except Exception:
#             pass
# 
#         st.success("Transcription complete")
#         st.text_area("Transcribed Text (copy into main input area if you want to generate audiobook from it)", value=detected_text, height=150)
# 
#     except Exception as e:
#         st.error(f"Error processing audio: {e}")
#

!pkill -f ngrok



!pkill -f streamlit  # stop previous processes

import time

# Run streamlit in background
!nohup streamlit run app.py --server.port 8501 > streamlit.log 2>&1 &

time.sleep(5)  # wait for server to start

public_url = ngrok.connect(8501)
print("âœ… Streamlit app running at:", public_url)

